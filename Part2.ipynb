{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd668df-56a5-4724-b971-cf441a4761f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import numpy as np\n",
    "import logging\n",
    "import warnings\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Set up logging and warnings\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df450317-0a27-43fc-8247-50555751196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-medium')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89e30272-3614-4e58-a8d6-72d8268ddf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_from_top(probs, n=5):\n",
    "    ind = np.argpartition(probs, -n)[-n:]\n",
    "    top_prob = probs[ind]\n",
    "    top_prob = top_prob / np.sum(top_prob)  # Normalize\n",
    "    choice = np.random.choice(n, 1, p=top_prob)\n",
    "    token_id = ind[choice][0]\n",
    "    return int(token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efe92178-b708-4f0d-b522-54c99b4915d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, lyrics_dataset_path='song_lyrics.csv'):\n",
    "        super().__init__()\n",
    "        self.lyrics_list = []\n",
    "        self.end_of_text_token = tokenizer.eos_token\n",
    "\n",
    "        with open(lyrics_dataset_path, encoding='utf-8') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file)\n",
    "            for row in csv_reader:\n",
    "                lyric_str = f\"SONG:{row[1]}{self.end_of_text_token}\"\n",
    "                self.lyrics_list.append(lyric_str)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lyrics_list)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.lyrics_list[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae61b8df-09be-46b9-9469-f748fb94298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LyricsDataset('SelenaGomez.csv')\n",
    "lyrics_loader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5243b11-e59e-404f-899a-bce3067dbe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 3e-5\n",
    "WARMUP_STEPS = 5000\n",
    "MAX_SEQ_LEN = 400\n",
    "\n",
    "# Optimizer and scheduler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ade8a9d3-4d48-46c4-8097-5a487ec51e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 started==============================\n",
      "EPOCH 1 started==============================\n",
      "EPOCH 2 started==============================\n",
      "EPOCH 3 started==============================\n",
      "EPOCH 4 started==============================\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=-1)\n",
    "\n",
    "# Training loop\n",
    "proc_seq_count = 0\n",
    "sum_loss = 0.0\n",
    "batch_count = 0\n",
    "tmp_lyrics_tens = None\n",
    "models_folder = \"trained_models\"\n",
    "\n",
    "if not os.path.exists(models_folder):\n",
    "    os.mkdir(models_folder)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"EPOCH {epoch} started\" + '=' * 30)\n",
    "    \n",
    "    for idx, lyric in enumerate(lyrics_loader):\n",
    "        lyric_tens = torch.tensor(tokenizer.encode(lyric[0])).unsqueeze(0).to(device)\n",
    "        \n",
    "        if lyric_tens.size()[1] > MAX_SEQ_LEN:\n",
    "            continue\n",
    "        \n",
    "        if not torch.is_tensor(tmp_lyrics_tens):\n",
    "            tmp_lyrics_tens = lyric_tens\n",
    "            continue\n",
    "        else:\n",
    "            if tmp_lyrics_tens.size()[1] + lyric_tens.size()[1] > MAX_SEQ_LEN:\n",
    "                work_lyrics_tens = tmp_lyrics_tens\n",
    "                tmp_lyrics_tens = lyric_tens\n",
    "            else:\n",
    "                tmp_lyrics_tens = torch.cat([tmp_lyrics_tens, lyric_tens[:, 1:]], dim=1)\n",
    "                continue\n",
    "        \n",
    "        outputs = model(work_lyrics_tens, labels=work_lyrics_tens)\n",
    "        loss, logits = outputs[:2]\n",
    "        loss.backward()\n",
    "        sum_loss += loss.detach().data\n",
    "        \n",
    "        proc_seq_count += 1\n",
    "        if proc_seq_count == BATCH_SIZE:\n",
    "            proc_seq_count = 0\n",
    "            batch_count += 1\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            model.zero_grad()\n",
    "\n",
    "        if batch_count == 100:\n",
    "            print(f\"sum loss {sum_loss}\")\n",
    "            batch_count = 0\n",
    "            sum_loss = 0.0\n",
    "    \n",
    "    # Save model after each epoch\n",
    "    try:\n",
    "        torch.save(model.state_dict(), os.path.join(models_folder, f\"gpt2_medium_lyrics_{epoch}.pt\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49ae3358-a795-452a-9cbd-daa3210971ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.core.framework.types_pb2' has no attribute 'SerializedDType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m lyrics_num \u001b[38;5;241m=\u001b[39m lyrics_num \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     43\u001b[0m output_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(cur_ids\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m---> 44\u001b[0m output_text \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(lyrics_output_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     47\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\pythonlab\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3834\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[1;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m \u001b[38;5;124;03mConverts a sequence of ids in a string, using the tokenizer and vocabulary with options to remove special\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m \u001b[38;5;124;03mtokens and clean up tokenization spaces.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3831\u001b[0m \u001b[38;5;124;03m    `str`: The decoded sentence.\u001b[39;00m\n\u001b[0;32m   3832\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3833\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[1;32m-> 3834\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m \u001b[43mto_py_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3836\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(\n\u001b[0;32m   3837\u001b[0m     token_ids\u001b[38;5;241m=\u001b[39mtoken_ids,\n\u001b[0;32m   3838\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens,\n\u001b[0;32m   3839\u001b[0m     clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39mclean_up_tokenization_spaces,\n\u001b[0;32m   3840\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3841\u001b[0m )\n",
      "File \u001b[1;32m~\\pythonlab\\lib\\site-packages\\transformers\\utils\\generic.py:268\u001b[0m, in \u001b[0;36mto_py_obj\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: to_py_obj(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [to_py_obj(o) \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m obj]\n\u001b[0;32m    270\u001b[0m \u001b[38;5;66;03m# This gives us a smart order to test the frameworks with the corresponding tests.\u001b[39;00m\n\u001b[0;32m    271\u001b[0m framework_to_test_func \u001b[38;5;241m=\u001b[39m _get_frameworks_and_test_func(obj)\n",
      "File \u001b[1;32m~\\pythonlab\\lib\\site-packages\\transformers\\utils\\generic.py:268\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: to_py_obj(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mto_py_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m obj]\n\u001b[0;32m    270\u001b[0m \u001b[38;5;66;03m# This gives us a smart order to test the frameworks with the corresponding tests.\u001b[39;00m\n\u001b[0;32m    271\u001b[0m framework_to_test_func \u001b[38;5;241m=\u001b[39m _get_frameworks_and_test_func(obj)\n",
      "File \u001b[1;32m~\\pythonlab\\lib\\site-packages\\transformers\\utils\\generic.py:273\u001b[0m, in \u001b[0;36mto_py_obj\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    271\u001b[0m framework_to_test_func \u001b[38;5;241m=\u001b[39m _get_frameworks_and_test_func(obj)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m framework, test_func \u001b[38;5;129;01min\u001b[39;00m framework_to_test_func\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 273\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtest_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    274\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m framework_to_py_obj[framework](obj)\n\u001b[0;32m    276\u001b[0m \u001b[38;5;66;03m# tolist also works on 0d np arrays\u001b[39;00m\n",
      "File \u001b[1;32m~\\pythonlab\\lib\\site-packages\\transformers\\utils\\generic.py:207\u001b[0m, in \u001b[0;36mis_tf_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_tf_tensor\u001b[39m(x):\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    Tests if `x` is a tensorflow tensor or not. Safe to call even if tensorflow is not installed.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_is_tensorflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\pythonlab\\lib\\site-packages\\transformers\\utils\\generic.py:198\u001b[0m, in \u001b[0;36m_is_tensorflow\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_tensorflow\u001b[39m(x):\n\u001b[1;32m--> 198\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, tf\u001b[38;5;241m.\u001b[39mTensor)\n",
      "File \u001b[1;32m~\\pythonlab\\lib\\site-packages\\tensorflow\\__init__.py:41\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_six\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32m~\\pythonlab\\lib\\site-packages\\tensorflow\\python\\__init__.py:37\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[1;32m~\\pythonlab\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tf_session\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cancellation\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m execute\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m executor\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m monitoring\n",
      "File \u001b[1;32m~\\pythonlab\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tfe\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_conversion_registry\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n",
      "File \u001b[1;32m~\\pythonlab\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:49\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDTypeMeta\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m(_dtypes\u001b[38;5;241m.\u001b[39mDType), abc\u001b[38;5;241m.\u001b[39mABCMeta):\n\u001b[0;32m     45\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtypes.DType\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDType\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDType\u001b[39;00m(\n\u001b[0;32m     50\u001b[0m     _dtypes\u001b[38;5;241m.\u001b[39mDType,\n\u001b[0;32m     51\u001b[0m     trace\u001b[38;5;241m.\u001b[39mTraceType,\n\u001b[0;32m     52\u001b[0m     trace_type\u001b[38;5;241m.\u001b[39mSerializable,\n\u001b[0;32m     53\u001b[0m     metaclass\u001b[38;5;241m=\u001b[39mDTypeMeta):\n\u001b[0;32m     54\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Represents the type of the elements in a `Tensor`.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m  `DType`'s are used to specify the output data type for operations which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m  See `tf.dtypes` for a complete list of `DType`'s defined.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m   \u001b[38;5;18m__slots__\u001b[39m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_handle_data\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\pythonlab\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:235\u001b[0m, in \u001b[0;36mDType\u001b[1;34m()\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"TensorShape does not support placeholder values.\"\"\"\u001b[39;00m\n\u001b[0;32m    232\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m--> 235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexperimental_type_proto\u001b[39m(\u001b[38;5;28mcls\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Type[\u001b[43mtypes_pb2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializedDType\u001b[49m]:\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the type of proto associated with DType serialization.\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m types_pb2\u001b[38;5;241m.\u001b[39mSerializedDType\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.core.framework.types_pb2' has no attribute 'SerializedDType'"
     ]
    }
   ],
   "source": [
    "MODEL_EPOCH = 4\n",
    "\n",
    "models_folder = \"trained_models\"\n",
    "\n",
    "model_path = os.path.join(models_folder, f\"gpt2_medium_lyrics_{MODEL_EPOCH}.pt\")\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "lyrics_output_file_path = f'generated_{MODEL_EPOCH}.lyrics'\n",
    "\n",
    "model.eval()\n",
    "if os.path.exists(lyrics_output_file_path):\n",
    "    os.remove(lyrics_output_file_path)\n",
    "    \n",
    "lyrics_num = 0\n",
    "with torch.no_grad():\n",
    "   \n",
    "        for lyrics_idx in range(1000):\n",
    "        \n",
    "            lyrics_finished = False\n",
    "\n",
    "            cur_ids = torch.tensor(tokenizer.encode(\"SONG:\")).unsqueeze(0).to(device)\n",
    "\n",
    "            for i in range(100):\n",
    "                outputs = model(cur_ids, labels=cur_ids)\n",
    "                loss, logits = outputs[:2]\n",
    "                softmax_logits = torch.softmax(logits[0,-1], dim=0) #Take the first(from only one in this case) batch and the last predicted embedding\n",
    "                if i < 3:\n",
    "                    n = 20\n",
    "                else:\n",
    "                    n = 3\n",
    "                next_token_id = choose_from_top(softmax_logits.to('cpu').numpy(), n=n) #Randomly(from the topN probability distribution) select the next word\n",
    "                cur_ids = torch.cat([cur_ids, torch.ones((1,1)).long().to(device) * next_token_id], dim = 1) # Add the last word to the running sequence\n",
    "\n",
    "                if next_token_id in tokenizer.encode('<|endoftext|>'):\n",
    "                    lyrics_finished = True\n",
    "                    break\n",
    "\n",
    "            \n",
    "            if lyrics_finished:\n",
    "                \n",
    "                lyrics_num = lyrics_num + 1\n",
    "                \n",
    "                output_list = list(cur_ids.squeeze().to('cpu').numpy())\n",
    "                output_text = tokenizer.decode(output_list)\n",
    "\n",
    "                with open(lyrics_output_file_path, 'a') as f:\n",
    "                    f.write(f\"{output_text} \\n\\n\")\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68a84f5-f0a3-4f05-9cc8-a2ece8c984d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
