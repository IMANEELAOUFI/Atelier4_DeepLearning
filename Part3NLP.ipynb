{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8522281,"sourceType":"datasetVersion","datasetId":5088699}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom transformers import BertModel, BertTokenizer\nimport json\nimport pandas as pd\nimport gzip\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\nfrom transformers import BertTokenizer, BertForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2024-05-26T14:02:50.350683Z","iopub.execute_input":"2024-05-26T14:02:50.351432Z","iopub.status.idle":"2024-05-26T14:02:50.356312Z","shell.execute_reply.started":"2024-05-26T14:02:50.351402Z","shell.execute_reply":"2024-05-26T14:02:50.355379Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-26T14:02:52.200466Z","iopub.execute_input":"2024-05-26T14:02:52.200834Z","iopub.status.idle":"2024-05-26T14:02:52.207249Z","shell.execute_reply.started":"2024-05-26T14:02:52.200804Z","shell.execute_reply":"2024-05-26T14:02:52.206220Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"# Step 1: Load Data from JSON File\ndef parse(path):\n  g = open(path, 'rb')\n  for l in g:\n    yield json.loads(l)\n\ndef getDF(path):\n  i = 0\n  df = {}\n  for d in parse(path):\n    df[i] = d\n    i += 1\n  return pd.DataFrame.from_dict(df, orient='index')\n\n\ndf = getDF(r'/kaggle/input/amazon-fashion-5/AMAZON_FASHION_5.json')\ndf = df[df[\"reviewText\"].apply(lambda x: isinstance(x, str))]","metadata":{"execution":{"iopub.status.busy":"2024-05-26T14:03:15.086447Z","iopub.execute_input":"2024-05-26T14:03:15.086805Z","iopub.status.idle":"2024-05-26T14:03:15.153490Z","shell.execute_reply.started":"2024-05-26T14:03:15.086777Z","shell.execute_reply":"2024-05-26T14:03:15.152413Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"input_texts = df[\"reviewText\"].tolist()\nlabels = df[\"overall\"].tolist()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T14:03:18.394374Z","iopub.execute_input":"2024-05-26T14:03:18.394741Z","iopub.status.idle":"2024-05-26T14:03:18.400145Z","shell.execute_reply.started":"2024-05-26T14:03:18.394711Z","shell.execute_reply":"2024-05-26T14:03:18.399187Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model_name = \"bert-base-uncased\"\ntokenizer = BertTokenizer.from_pretrained(model_name)\nencoded_inputs = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T14:03:20.868341Z","iopub.execute_input":"2024-05-26T14:03:20.869064Z","iopub.status.idle":"2024-05-26T14:03:25.097207Z","shell.execute_reply.started":"2024-05-26T14:03:20.869032Z","shell.execute_reply":"2024-05-26T14:03:25.096188Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"labels = torch.tensor(labels, dtype=torch.float32).unsqueeze(1)\ndataset = TensorDataset(encoded_inputs['input_ids'], encoded_inputs['attention_mask'], labels)\n\ntrain_size = int(0.8 * len(dataset))\neval_size = len(dataset) - train_size\ntrain_dataset, eval_dataset = random_split(dataset, [train_size, eval_size])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T14:03:28.042093Z","iopub.execute_input":"2024-05-26T14:03:28.042960Z","iopub.status.idle":"2024-05-26T14:03:28.049497Z","shell.execute_reply.started":"2024-05-26T14:03:28.042928Z","shell.execute_reply":"2024-05-26T14:03:28.048511Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"batch_size = 8\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\neval_loader = DataLoader(eval_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T14:03:30.112246Z","iopub.execute_input":"2024-05-26T14:03:30.112956Z","iopub.status.idle":"2024-05-26T14:03:30.118393Z","shell.execute_reply.started":"2024-05-26T14:03:30.112923Z","shell.execute_reply":"2024-05-26T14:03:30.117405Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nbert_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=1).to(device)\noptimizer = torch.optim.AdamW(bert_model.parameters(), lr=2e-5)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T14:03:32.246887Z","iopub.execute_input":"2024-05-26T14:03:32.247508Z","iopub.status.idle":"2024-05-26T14:03:32.924516Z","shell.execute_reply.started":"2024-05-26T14:03:32.247479Z","shell.execute_reply":"2024-05-26T14:03:32.923580Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"num_epochs = 3\nfor epoch in range(num_epochs):\n    # Training\n    bert_model.train()\n    total_train_loss = 0.0\n    num_train_batches = 0\n    for batch in train_loader:\n        input_ids, attention_mask, label = [t.to(device) for t in batch]\n        optimizer.zero_grad()\n        outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask, labels=label)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        total_train_loss += loss.item()\n        num_train_batches += 1\n    avg_train_loss = total_train_loss / num_train_batches\n\n    # Evaluation\n    bert_model.eval()\n    total_eval_loss = 0.0\n    num_eval_batches = 0\n    with torch.no_grad():\n        for batch in eval_loader:\n            input_ids, attention_mask, label = [t.to(device) for t in batch]\n            outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask, labels=label)\n            total_eval_loss += outputs.loss.item()\n            num_eval_batches += 1\n    avg_eval_loss = total_eval_loss / num_eval_batches\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}, Evaluation Loss: {avg_eval_loss:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T14:03:35.525038Z","iopub.execute_input":"2024-05-26T14:03:35.525391Z","iopub.status.idle":"2024-05-26T14:08:19.345068Z","shell.execute_reply.started":"2024-05-26T14:03:35.525360Z","shell.execute_reply":"2024-05-26T14:08:19.343981Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Epoch [1/3], Training Loss: 1.1162, Evaluation Loss: 0.1257\nEpoch [2/3], Training Loss: 0.0904, Evaluation Loss: 0.0775\nEpoch [3/3], Training Loss: 0.0530, Evaluation Loss: 0.0525\n","output_type":"stream"}]},{"cell_type":"code","source":"review_text = \"I dont like it\"\n\ntokenized_review = tokenizer(review_text, padding=True, truncation=True, return_tensors='pt')\n\ninput_ids = tokenized_review['input_ids'].to(device)\nattention_mask = tokenized_review['attention_mask'].to(device)\n\nwith torch.no_grad():\n    bert_model.eval()\n    outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n    predicted_rating = outputs.logits.item()\n\nprint(f\"Predicted rating: {predicted_rating:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T14:09:08.814826Z","iopub.execute_input":"2024-05-26T14:09:08.815616Z","iopub.status.idle":"2024-05-26T14:09:08.835501Z","shell.execute_reply.started":"2024-05-26T14:09:08.815586Z","shell.execute_reply":"2024-05-26T14:09:08.834651Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Predicted rating: 2.73\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}